{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "load_data.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtbjSpzCOsU9"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co4fCKS8OsVC"
      },
      "source": [
        "# len(train_X) = 154684\n",
        "train_X = np.load('train_X.npy', allow_pickle = True)[:110000]\n",
        "train_Y = np.load('train_Y.npy', allow_pickle = True)[:110000]\n",
        "val_X = np.load('train_X.npy', allow_pickle = True)[110000:]\n",
        "val_Y = np.load('train_Y.npy', allow_pickle = True)[110000:]\n",
        "test_X = np.load('test_X.npy', allow_pickle = True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Cpz_bdOsVH"
      },
      "source": [
        "# custom Dataset class\n",
        "class MovieReviewsData(Dataset):\n",
        "    def __init__(self, X, Y = None):\n",
        "        self.maxlen = max(len(x) for x in X)\n",
        "        self.X = [F.pad(torch.FloatTensor(x), (0, 0, 0, self.maxlen - len(x))) for x in X]\n",
        "        if Y is not None:\n",
        "            self.Y = torch.LongTensor(Y)\n",
        "        else:\n",
        "            self.Y = None\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.Y is not None:\n",
        "            return self.X[idx], self.Y[idx]\n",
        "        else:\n",
        "            return self.X[idx]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6ZcdaotOsVK"
      },
      "source": [
        "train_dataset = MovieReviewsData(train_X, train_Y)\n",
        "val_dataset = MovieReviewsData(val_X, val_Y)\n",
        "test_dataset = MovieReviewsData(test_X)\n",
        "train_loader = DataLoader(train_dataset, shuffle = True, batch_size = BATCH_SIZE)\n",
        "val_loader = DataLoader(val_dataset, shuffle = False, batch_size = BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = BATCH_SIZE)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5iolhO4OsVN"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, input_channel, out_channel, kernel_sizes, output_dim):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = input_channel, \n",
        "                                              out_channels = out_channel, \n",
        "                                              kernel_size = ks)\n",
        "                                    for ks in kernel_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.linear = nn.Linear(len(kernel_sizes) * out_channel, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, embedded):     \n",
        "        embedded = embedded.permute(0, 2, 1)       \n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        return self.linear(cat)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3CyG5oEYgoa"
      },
      "source": [
        "input_channel = 300\n",
        "out_channel = 100\n",
        "#[3,4,5]\n",
        "kernel_sizes = [3,4,5]\n",
        "output_dim = 5\n",
        "\n",
        "model = Network(input_channel, out_channel, kernel_sizes, output_dim)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL6bbVZyZDw0"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 3e-4, weight_decay=5e-6)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNxhDR-8aTWf"
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    start_time = time.time()\n",
        "    for batch_idx, (X, Y) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   \n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device) \n",
        "\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, Y)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    return running_loss\n",
        "\n",
        "def test_model(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "\n",
        "        for batch_idx, (X, Y) in enumerate(test_loader):   \n",
        "            X = X.to(device)\n",
        "            Y = Y.to(device) \n",
        "\n",
        "            outputs = model(X)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += Y.size(0)\n",
        "            correct_predictions += (predicted == Y).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, Y)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "\n",
        "        running_loss /= len(test_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        print('Testing Loss: ', running_loss)\n",
        "        print('Testing Accuracy: ', acc, '%')\n",
        "        return running_loss, acc"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUoeuWi_b8a8",
        "outputId": "52968bea-4f37-41d1-cbd3-e53df7feb7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs = 40\n",
        "Train_loss = []\n",
        "Test_loss = []\n",
        "Test_acc = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    print(\"epoch\" + str(i+1))\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_acc = test_model(model, val_loader, criterion)\n",
        "    Train_loss.append(train_loss)\n",
        "    Test_loss.append(test_loss)\n",
        "    Test_acc.append(test_acc)\n",
        "    print('='*20)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch1\n",
            "Training Loss:  0.9981650737845114 Time:  10.114025592803955 s\n",
            "Testing Loss:  0.9750969044981426\n",
            "Testing Accuracy:  59.84692507385194 %\n",
            "====================\n",
            "epoch2\n",
            "Training Loss:  0.8802105935594937 Time:  10.253650188446045 s\n",
            "Testing Loss:  0.9645662034444713\n",
            "Testing Accuracy:  60.18709157640318 %\n",
            "====================\n",
            "epoch3\n",
            "Training Loss:  0.8402884633406572 Time:  10.063617467880249 s\n",
            "Testing Loss:  0.9642193938188457\n",
            "Testing Accuracy:  60.43550264076627 %\n",
            "====================\n",
            "epoch4\n",
            "Training Loss:  0.8084179241342417 Time:  9.906652450561523 s\n",
            "Testing Loss:  0.9662365742848495\n",
            "Testing Accuracy:  60.43326470324949 %\n",
            "====================\n",
            "epoch5\n",
            "Training Loss:  0.7869884031952086 Time:  10.21966552734375 s\n",
            "Testing Loss:  0.9713889212908492\n",
            "Testing Accuracy:  60.2855608271417 %\n",
            "====================\n",
            "epoch6\n",
            "Training Loss:  0.7671053087628117 Time:  10.20749807357788 s\n",
            "Testing Loss:  0.9784915219560714\n",
            "Testing Accuracy:  60.386268015397015 %\n",
            "====================\n",
            "epoch7\n",
            "Training Loss:  0.755858491089817 Time:  10.403058052062988 s\n",
            "Testing Loss:  0.9876518500209366\n",
            "Testing Accuracy:  60.572016829290135 %\n",
            "====================\n",
            "epoch8\n",
            "Training Loss:  0.7399148597767216 Time:  10.138832092285156 s\n",
            "Testing Loss:  0.9831283787459945\n",
            "Testing Accuracy:  60.64810670486081 %\n",
            "====================\n",
            "epoch9\n",
            "Training Loss:  0.729693463907608 Time:  10.061514854431152 s\n",
            "Testing Loss:  0.9958739206941002\n",
            "Testing Accuracy:  60.37060245277952 %\n",
            "====================\n",
            "epoch10\n",
            "Training Loss:  0.7206577463091772 Time:  10.084557294845581 s\n",
            "Testing Loss:  0.9996757259611067\n",
            "Testing Accuracy:  60.04833945036254 %\n",
            "====================\n",
            "epoch11\n",
            "Training Loss:  0.7140478251318796 Time:  10.279361963272095 s\n",
            "Testing Loss:  0.9985693108199833\n",
            "Testing Accuracy:  60.361650702712375 %\n",
            "====================\n",
            "epoch12\n",
            "Training Loss:  0.7065992704514087 Time:  10.26962423324585 s\n",
            "Testing Loss:  1.003082919018463\n",
            "Testing Accuracy:  60.39298182794737 %\n",
            "====================\n",
            "epoch13\n",
            "Training Loss:  0.7018196327420013 Time:  10.217378377914429 s\n",
            "Testing Loss:  1.008748757651606\n",
            "Testing Accuracy:  60.45340614090055 %\n",
            "====================\n",
            "epoch14\n",
            "Training Loss:  0.6943114291900393 Time:  10.112563848495483 s\n",
            "Testing Loss:  1.006889114180348\n",
            "Testing Accuracy:  60.58320651687404 %\n",
            "====================\n",
            "epoch15\n",
            "Training Loss:  0.689568025920889 Time:  10.434496641159058 s\n",
            "Testing Loss:  1.0088929265780169\n",
            "Testing Accuracy:  60.50264076626981 %\n",
            "====================\n",
            "epoch16\n",
            "Training Loss:  0.6824041217513526 Time:  10.335306406021118 s\n",
            "Testing Loss:  1.0231042193923043\n",
            "Testing Accuracy:  60.3437472025781 %\n",
            "====================\n",
            "epoch17\n",
            "Training Loss:  0.679921765688757 Time:  10.043163537979126 s\n",
            "Testing Loss:  1.0231292926531834\n",
            "Testing Accuracy:  60.663772267478286 %\n",
            "====================\n",
            "epoch18\n",
            "Training Loss:  0.6759171045367423 Time:  9.999770879745483 s\n",
            "Testing Loss:  1.0302307106053539\n",
            "Testing Accuracy:  60.51383045385372 %\n",
            "====================\n",
            "epoch19\n",
            "Training Loss:  0.6697154694202683 Time:  10.189979791641235 s\n",
            "Testing Loss:  1.0315726863297612\n",
            "Testing Accuracy:  60.35717482767882 %\n",
            "====================\n",
            "epoch20\n",
            "Training Loss:  0.6700805063473755 Time:  9.9043128490448 s\n",
            "Testing Loss:  1.0367499136703038\n",
            "Testing Accuracy:  60.30794020230955 %\n",
            "====================\n",
            "epoch21\n",
            "Training Loss:  0.6651046744191834 Time:  9.986075401306152 s\n",
            "Testing Loss:  1.0365110086610219\n",
            "Testing Accuracy:  60.3303195774774 %\n",
            "====================\n",
            "epoch22\n",
            "Training Loss:  0.6606941320925275 Time:  9.831685304641724 s\n",
            "Testing Loss:  1.0450422816266318\n",
            "Testing Accuracy:  60.41536120311521 %\n",
            "====================\n",
            "epoch23\n",
            "Training Loss:  0.6571494930008249 Time:  9.907646417617798 s\n",
            "Testing Loss:  1.0474275848981478\n",
            "Testing Accuracy:  60.155760451168206 %\n",
            "====================\n",
            "epoch24\n",
            "Training Loss:  0.6554037072826361 Time:  9.868801593780518 s\n",
            "Testing Loss:  1.0497895764008442\n",
            "Testing Accuracy:  60.22289857667174 %\n",
            "====================\n",
            "epoch25\n",
            "Training Loss:  0.6521445727403806 Time:  9.802117347717285 s\n",
            "Testing Loss:  1.0611277465656592\n",
            "Testing Accuracy:  60.22066063915496 %\n",
            "====================\n",
            "epoch26\n",
            "Training Loss:  0.6467911537613128 Time:  9.679381608963013 s\n",
            "Testing Loss:  1.054735242211938\n",
            "Testing Accuracy:  60.22289857667174 %\n",
            "====================\n",
            "epoch27\n",
            "Training Loss:  0.6459280623121966 Time:  9.668952703475952 s\n",
            "Testing Loss:  1.057475102902823\n",
            "Testing Accuracy:  60.18932951391997 %\n",
            "====================\n",
            "epoch28\n",
            "Training Loss:  0.6428088976277245 Time:  10.299486875534058 s\n",
            "Testing Loss:  1.0562550990025543\n",
            "Testing Accuracy:  60.29227463969205 %\n",
            "====================\n",
            "epoch29\n",
            "Training Loss:  0.6415798654731032 Time:  10.116879224777222 s\n",
            "Testing Loss:  1.0751255415113528\n",
            "Testing Accuracy:  59.983439262375796 %\n",
            "====================\n",
            "epoch30\n",
            "Training Loss:  0.6399035516903108 Time:  10.109333753585815 s\n",
            "Testing Loss:  1.0707542140766957\n",
            "Testing Accuracy:  60.23632620177245 %\n",
            "====================\n",
            "epoch31\n",
            "Training Loss:  0.6386415698002632 Time:  10.143654346466064 s\n",
            "Testing Loss:  1.0645510575631487\n",
            "Testing Accuracy:  60.29003670217528 %\n",
            "====================\n",
            "epoch32\n",
            "Training Loss:  0.6358477590977278 Time:  10.047870874404907 s\n",
            "Testing Loss:  1.071343538160829\n",
            "Testing Accuracy:  60.09981201324859 %\n",
            "====================\n",
            "epoch33\n",
            "Training Loss:  0.6328743060637935 Time:  10.163125038146973 s\n",
            "Testing Loss:  1.0803574557723916\n",
            "Testing Accuracy:  60.086384388147884 %\n",
            "====================\n",
            "epoch34\n",
            "Training Loss:  0.6293740917978903 Time:  10.269695043563843 s\n",
            "Testing Loss:  1.079472052479677\n",
            "Testing Accuracy:  60.265419389490646 %\n",
            "====================\n",
            "epoch35\n",
            "Training Loss:  0.6290572894874737 Time:  10.398370027542114 s\n",
            "Testing Loss:  1.0747792683701658\n",
            "Testing Accuracy:  60.10652582579894 %\n",
            "====================\n",
            "epoch36\n",
            "Training Loss:  0.626844621713665 Time:  10.413121700286865 s\n",
            "Testing Loss:  1.080515690499621\n",
            "Testing Accuracy:  60.43774057828305 %\n",
            "====================\n",
            "epoch37\n",
            "Training Loss:  0.6233097918335957 Time:  10.209297180175781 s\n",
            "Testing Loss:  1.0781746097388698\n",
            "Testing Accuracy:  60.12666726345001 %\n",
            "====================\n",
            "epoch38\n",
            "Training Loss:  0.6233497350939905 Time:  10.828882694244385 s\n",
            "Testing Loss:  1.0812425427511867\n",
            "Testing Accuracy:  60.30346432727598 %\n",
            "====================\n",
            "epoch39\n",
            "Training Loss:  0.6204540269051686 Time:  10.475074768066406 s\n",
            "Testing Loss:  1.0818346833466461\n",
            "Testing Accuracy:  60.23856413928923 %\n",
            "====================\n",
            "epoch40\n",
            "Training Loss:  0.6194511789822037 Time:  10.492148399353027 s\n",
            "Testing Loss:  1.0915235910719214\n",
            "Testing Accuracy:  60.05729120042969 %\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkVlU56HcBjr"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}