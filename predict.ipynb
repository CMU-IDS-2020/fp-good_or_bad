{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_yoer6Nged_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379372d1-9f10-4aa2-9935-af278050ed7c"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import nltk\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from torch.nn.functional import pad\n",
        "import zipfile\n",
        "import os\n",
        "from os import listdir\n",
        "from zipfile import ZipFile\n",
        "from os.path import isfile, join\n",
        "cuda = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTiqwM_jr82"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, input_channel, out_channel, kernel_sizes, output_dim):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = input_channel, \n",
        "                                              out_channels = out_channel, \n",
        "                                              kernel_size = ks)\n",
        "                                    for ks in kernel_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.linear = nn.Linear(len(kernel_sizes) * out_channel, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, embedded):     \n",
        "        embedded = embedded.permute(0, 2, 1)       \n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        return self.linear(cat)\n",
        "input_channel = 300\n",
        "out_channel = 100\n",
        "kernel_sizes = [3,4,5]\n",
        "output_dim = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m57o8XB-giM"
      },
      "source": [
        "# !wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "# !unzip *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew3HwYMTGN3S"
      },
      "source": [
        "# read GloVe\n",
        "# citation: https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
        "def loadGloveModel(File):\n",
        "    print(\"Loading Glove Model\")\n",
        "    with open(File, 'r', encoding='utf-8') as f:\n",
        "        gloveModel = {}\n",
        "        for line in f:\n",
        "            splitLines = line.split()\n",
        "            word = splitLines[0]\n",
        "            wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
        "            gloveModel[word] = wordEmbedding\n",
        "        print(len(gloveModel),\" words loaded!\")\n",
        "        return gloveModel\n",
        "# word2vec_dict = loadGloveModel(\"./glove.42B.300d.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmkJzmw8h5Vj",
        "outputId": "bfde5209-c224-44d4-bd1f-5beb50cd93bb"
      },
      "source": [
        "#predict\n",
        "def tokenize_sentence(sentence, word2vec_dict):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    lemmatizer = WordNetLemmatizer() \n",
        "    english_stopwords = stopwords.words('english')\n",
        "    sentence = sentence.strip()\n",
        "    tokenized_sentence = [lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(sentence) if token.lower() in word2vec_dict and token.lower() not in english_stopwords]\n",
        "    return tokenized_sentence\n",
        "\n",
        "def load_word2vec_dict(word2vec_dir):\n",
        "  files = [join(word2vec_dir, f) for f in listdir(word2vec_dir) if isfile(join(word2vec_dir, f)) and not f.endswith(\".zip\")]\n",
        "  if not files:\n",
        "    zipfiles = [join(word2vec_dir, f) for f in listdir(word2vec_dir) if isfile(join(word2vec_dir, f)) and f.endswith(\".zip\")]\n",
        "    for f in zipfiles:\n",
        "      with zipfile.ZipFile(f,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(word2vec_dir)\n",
        "    files = [join(word2vec_dir, f) for f in listdir(word2vec_dir) if isfile(join(word2vec_dir, f)) and not f.endswith(\".zip\")]\n",
        "    start = time.time()\n",
        "  word2vec_dict = []\n",
        "  for path in files:\n",
        "    word2vec = torch.load(path)\n",
        "    word2vec_dict += list(word2vec.items())\n",
        "  return dict(word2vec_dict)\n",
        "      \n",
        "def predict(sentence, model_path = \"./models/xentropy_adam_lr0.0001_wd0.0005_bs128\", word2vec_dict_dir = \"./word2vec\",max_seq_length = 29):\n",
        "  word2vec_dict = load_word2vec_dict(word2vec_dict_dir)\n",
        "  tokenized_sentence = tokenize_sentence(sentence,word2vec_dict)\n",
        "  embedding = np.array([word2vec_dict[word] for word in tokenized_sentence])\n",
        "\n",
        "  temp = torch.load(model_path,map_location=torch.device('cpu'))  \n",
        "  model = Network(input_channel, out_channel, kernel_sizes, output_dim)\n",
        "  model.load_state_dict(temp['model_state_dict'])\n",
        "  model.eval()\n",
        "  \n",
        "  embedding = np.expand_dims(embedding,axis=0)\n",
        "  embedding = pad(torch.FloatTensor(embedding), (0, 0, 0, max_seq_length - len(embedding)))\n",
        "  outputs = model(embedding)\n",
        "  \n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  return outputs.data, predicted.item() + 1, embedding\n",
        "\n",
        "# Example: input: sentence  output: model_outputs, predicted_rating, sentence_embedding\n",
        "predict(\"what a wonderful movie! I love it!\")\n",
        "# predict(\"what a terrible movie! I hate it!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-5.6343, -4.9686, -2.3953,  3.4261,  5.1620]]),\n",
              " 5,\n",
              " tensor([[[-0.1407,  0.0105, -0.3944,  ...,  0.1503,  0.0072,  0.0554],\n",
              "          [-0.4207, -0.1447,  0.1019,  ...,  0.1122, -0.1660,  0.7195],\n",
              "          [-0.1493, -0.0068, -0.2495,  ..., -0.0461,  0.1480,  0.4215],\n",
              "          ...,\n",
              "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiI6KEMG5_jV"
      },
      "source": [
        "# word2vec_dict = torch.load(\"/content/drive/MyDrive/good_or_bad/word2vec/word2vec_dict_1\")\n",
        "# word2vec_list = list(word2vec_dict.items())\n",
        "# num = 4\n",
        "# per_cnt = len(word2vec_list) // num\n",
        "# os.chdir('/content/drive/MyDrive/good_or_bad/word2vec')\n",
        "# for i in range(num):\n",
        "#   if i == num-1:\n",
        "#     vec = dict(word2vec_list[i*per_cnt:])\n",
        "#   else:\n",
        "#     vec = dict(word2vec_list[i*per_cnt:(i+1)*per_cnt])\n",
        "#   file_name = \"word2vec_dict{}\".format(i+1)\n",
        "#   zip_file_name = \"word2vec_dict{}.zip\".format(i+1)\n",
        "#   torch.save(vec,file_name)\n",
        "#   ZipFile(zip_file_name, 'w').write(file_name)\n",
        "\n",
        "# os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}